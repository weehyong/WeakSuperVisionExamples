{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bitbaseconda27d2b9c7c5084099b6bffc706317a653",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Transformers to perform text classification\n",
    "\n",
    "\n",
    "Using Hugging Face NLP to perform text classification\n",
    "In this notebook, we show how to use  DistilBert and Long Transformers for performing text classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import torch\n",
    "import transformers as tfs\n",
    "from transformers import LongformerModel, LongformerTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         id                           node_id  \\\n0  61861755  MDEwOlJlcG9zaXRvcnk2MTg2MTc1NQ==   \n1  84138837  MDEwOlJlcG9zaXRvcnk4NDEzODgzNw==   \n2  63275452  MDEwOlJlcG9zaXRvcnk2MzI3NTQ1Mg==   \n3  81483877  MDEwOlJlcG9zaXRvcnk4MTQ4Mzg3Nw==   \n4  38904647  MDEwOlJlcG9zaXRvcnkzODkwNDY0Nw==   \n\n                              name                              full_name  \\\n0  alexa-skills-kit-sdk-for-nodejs  alexa/alexa-skills-kit-sdk-for-nodejs   \n1                   alexa-cookbook                   alexa/alexa-cookbook   \n2         skill-sample-nodejs-fact         alexa/skill-sample-nodejs-fact   \n3                   avs-device-sdk                   alexa/avs-device-sdk   \n4    alexa-skills-kit-sdk-for-java    alexa/alexa-skills-kit-sdk-for-java   \n\n   private                                              owner  \\\n0    False  {'login': 'alexa', 'id': 17815977, 'node_id': ...   \n1    False  {'login': 'alexa', 'id': 17815977, 'node_id': ...   \n2    False  {'login': 'alexa', 'id': 17815977, 'node_id': ...   \n3    False  {'login': 'alexa', 'id': 17815977, 'node_id': ...   \n4    False  {'login': 'alexa', 'id': 17815977, 'node_id': ...   \n\n                                            html_url  \\\n0  https://github.com/alexa/alexa-skills-kit-sdk-...   \n1            https://github.com/alexa/alexa-cookbook   \n2  https://github.com/alexa/skill-sample-nodejs-fact   \n3            https://github.com/alexa/avs-device-sdk   \n4  https://github.com/alexa/alexa-skills-kit-sdk-...   \n\n                                         description   fork  \\\n0  The Alexa Skills Kit SDK for Node.js helps you...  False   \n1  A series of sample code projects to be used fo...  False   \n2                          Build An Alexa Fact Skill  False   \n3  An SDK for commercial device makers to integra...  False   \n4  The Alexa Skills Kit SDK for Java helps you ge...  False   \n\n                                                 url  ... open_issues_count  \\\n0  https://api.github.com/repos/alexa/alexa-skill...  ...                 8   \n1  https://api.github.com/repos/alexa/alexa-cookbook  ...                13   \n2  https://api.github.com/repos/alexa/skill-sampl...  ...                 7   \n3  https://api.github.com/repos/alexa/avs-device-sdk  ...                54   \n4  https://api.github.com/repos/alexa/alexa-skill...  ...                 2   \n\n                                             license forks open_issues  \\\n0  {'key': 'apache-2.0', 'name': 'Apache License ...   670           8   \n1  {'key': 'other', 'name': 'Other', 'spdx_id': '...   912          13   \n2  {'key': 'apache-2.0', 'name': 'Apache License ...  1186           7   \n3  {'key': 'apache-2.0', 'name': 'Apache License ...   477          54   \n4  {'key': 'apache-2.0', 'name': 'Apache License ...   720           2   \n\n  watchers default_branch                                    permissions  \\\n0     2811          2.0.x  {'admin': False, 'push': False, 'pull': True}   \n1     1557         master  {'admin': False, 'push': False, 'pull': True}   \n2     1002         master  {'admin': False, 'push': False, 'pull': True}   \n3      993         master  {'admin': False, 'push': False, 'pull': True}   \n4      715          2.0.x  {'admin': False, 'push': False, 'pull': True}   \n\n  score                                             readme label  \n0     1  <p align=\"center\">\\n  <img src=\"https://m.medi...   API  \n1     1  \\n# Alexa Skill Building Cookbook\\n\\n<div styl...   API  \n2     1  # Build An Alexa Fact Skill\\n<img src=\"https:/...   API  \n3     1  ### What is the Alexa Voice Service (AVS)?\\n\\n...   API  \n4     1  <p align=\"center\">\\n  <img src=\"https://m.medi...   API  \n\n[5 rows x 77 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>node_id</th>\n      <th>name</th>\n      <th>full_name</th>\n      <th>private</th>\n      <th>owner</th>\n      <th>html_url</th>\n      <th>description</th>\n      <th>fork</th>\n      <th>url</th>\n      <th>...</th>\n      <th>open_issues_count</th>\n      <th>license</th>\n      <th>forks</th>\n      <th>open_issues</th>\n      <th>watchers</th>\n      <th>default_branch</th>\n      <th>permissions</th>\n      <th>score</th>\n      <th>readme</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>61861755</td>\n      <td>MDEwOlJlcG9zaXRvcnk2MTg2MTc1NQ==</td>\n      <td>alexa-skills-kit-sdk-for-nodejs</td>\n      <td>alexa/alexa-skills-kit-sdk-for-nodejs</td>\n      <td>False</td>\n      <td>{'login': 'alexa', 'id': 17815977, 'node_id': ...</td>\n      <td>https://github.com/alexa/alexa-skills-kit-sdk-...</td>\n      <td>The Alexa Skills Kit SDK for Node.js helps you...</td>\n      <td>False</td>\n      <td>https://api.github.com/repos/alexa/alexa-skill...</td>\n      <td>...</td>\n      <td>8</td>\n      <td>{'key': 'apache-2.0', 'name': 'Apache License ...</td>\n      <td>670</td>\n      <td>8</td>\n      <td>2811</td>\n      <td>2.0.x</td>\n      <td>{'admin': False, 'push': False, 'pull': True}</td>\n      <td>1</td>\n      <td>&lt;p align=\"center\"&gt;\\n  &lt;img src=\"https://m.medi...</td>\n      <td>API</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>84138837</td>\n      <td>MDEwOlJlcG9zaXRvcnk4NDEzODgzNw==</td>\n      <td>alexa-cookbook</td>\n      <td>alexa/alexa-cookbook</td>\n      <td>False</td>\n      <td>{'login': 'alexa', 'id': 17815977, 'node_id': ...</td>\n      <td>https://github.com/alexa/alexa-cookbook</td>\n      <td>A series of sample code projects to be used fo...</td>\n      <td>False</td>\n      <td>https://api.github.com/repos/alexa/alexa-cookbook</td>\n      <td>...</td>\n      <td>13</td>\n      <td>{'key': 'other', 'name': 'Other', 'spdx_id': '...</td>\n      <td>912</td>\n      <td>13</td>\n      <td>1557</td>\n      <td>master</td>\n      <td>{'admin': False, 'push': False, 'pull': True}</td>\n      <td>1</td>\n      <td>\\n# Alexa Skill Building Cookbook\\n\\n&lt;div styl...</td>\n      <td>API</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>63275452</td>\n      <td>MDEwOlJlcG9zaXRvcnk2MzI3NTQ1Mg==</td>\n      <td>skill-sample-nodejs-fact</td>\n      <td>alexa/skill-sample-nodejs-fact</td>\n      <td>False</td>\n      <td>{'login': 'alexa', 'id': 17815977, 'node_id': ...</td>\n      <td>https://github.com/alexa/skill-sample-nodejs-fact</td>\n      <td>Build An Alexa Fact Skill</td>\n      <td>False</td>\n      <td>https://api.github.com/repos/alexa/skill-sampl...</td>\n      <td>...</td>\n      <td>7</td>\n      <td>{'key': 'apache-2.0', 'name': 'Apache License ...</td>\n      <td>1186</td>\n      <td>7</td>\n      <td>1002</td>\n      <td>master</td>\n      <td>{'admin': False, 'push': False, 'pull': True}</td>\n      <td>1</td>\n      <td># Build An Alexa Fact Skill\\n&lt;img src=\"https:/...</td>\n      <td>API</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>81483877</td>\n      <td>MDEwOlJlcG9zaXRvcnk4MTQ4Mzg3Nw==</td>\n      <td>avs-device-sdk</td>\n      <td>alexa/avs-device-sdk</td>\n      <td>False</td>\n      <td>{'login': 'alexa', 'id': 17815977, 'node_id': ...</td>\n      <td>https://github.com/alexa/avs-device-sdk</td>\n      <td>An SDK for commercial device makers to integra...</td>\n      <td>False</td>\n      <td>https://api.github.com/repos/alexa/avs-device-sdk</td>\n      <td>...</td>\n      <td>54</td>\n      <td>{'key': 'apache-2.0', 'name': 'Apache License ...</td>\n      <td>477</td>\n      <td>54</td>\n      <td>993</td>\n      <td>master</td>\n      <td>{'admin': False, 'push': False, 'pull': True}</td>\n      <td>1</td>\n      <td>### What is the Alexa Voice Service (AVS)?\\n\\n...</td>\n      <td>API</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>38904647</td>\n      <td>MDEwOlJlcG9zaXRvcnkzODkwNDY0Nw==</td>\n      <td>alexa-skills-kit-sdk-for-java</td>\n      <td>alexa/alexa-skills-kit-sdk-for-java</td>\n      <td>False</td>\n      <td>{'login': 'alexa', 'id': 17815977, 'node_id': ...</td>\n      <td>https://github.com/alexa/alexa-skills-kit-sdk-...</td>\n      <td>The Alexa Skills Kit SDK for Java helps you ge...</td>\n      <td>False</td>\n      <td>https://api.github.com/repos/alexa/alexa-skill...</td>\n      <td>...</td>\n      <td>2</td>\n      <td>{'key': 'apache-2.0', 'name': 'Apache License ...</td>\n      <td>720</td>\n      <td>2</td>\n      <td>715</td>\n      <td>2.0.x</td>\n      <td>{'admin': False, 'push': False, 'pull': True}</td>\n      <td>1</td>\n      <td>&lt;p align=\"center\"&gt;\\n  &lt;img src=\"https://m.medi...</td>\n      <td>API</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 77 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Read the Amazon Github Hun repo files and show the first few rows\n",
    "amazonreviews_df = pd.read_json('./data/amazon_github_repos.json',lines=True)\n",
    "amazonreviews_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['API', 'RESEARCH', 'GENERAL', 'OTHER', 'DEAD'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Get the unique labels \n",
    "categories = amazonreviews_df.label.unique()\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "API         2265\nGENERAL      279\nDEAD          14\nRESEARCH       9\nOTHER          1\nName: label, dtype: int64"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# count each of the labels\n",
    "amazonreviews_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "API        2265\nGENERAL     279\nName: label, dtype: int64"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Focus on API and GENERAL labels only\n",
    "amazonreviews_df = amazonreviews_df[amazonreviews_df['label'].isin(['API', 'GENERAL'])]\n",
    "amazonreviews_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "API        2186\nGENERAL     259\nName: label, dtype: int64"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# remove rows that contain NA\n",
    "# Focus on API and GENERAL labels only\n",
    "amazonreviews_df = amazonreviews_df[amazonreviews_df['readme'].notna()]\n",
    "amazonreviews_df = amazonreviews_df[amazonreviews_df['label'].isin(['API', 'GENERAL'])]\n",
    "\n",
    "# count the number of rows after removing rows that contain NA, and only rows that has a label API, General\n",
    "amazonreviews_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    2186\n1     259\nName: labelcode, dtype: int64"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Convert labels to integers\n",
    "\n",
    "LE = LabelEncoder()\n",
    "amazonreviews_df['labelcode'] = LE.fit_transform(amazonreviews_df['label'])\n",
    "amazonreviews_df['labelcode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0    <p align=\"center\">\\n  <img src=\"https://m.medi...\n1    \\n# Alexa Skill Building Cookbook\\n\\n<div styl...\n2    # Build An Alexa Fact Skill\\n<img src=\"https:/...\n3    ### What is the Alexa Voice Service (AVS)?\\n\\n...\n4    <p align=\"center\">\\n  <img src=\"https://m.medi...\nName: readme, dtype: object\n"
    }
   ],
   "source": [
    "# Prepare training and test data\n",
    "\n",
    "\n",
    "# Drop the columns - label and fork \n",
    "# X = amazonreviews_df.drop(['label','fork'], axis=1)\n",
    "X = amazonreviews_df['readme']\n",
    "\n",
    "# What's in the Readme for the review\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the labels\n",
    "labels = amazonreviews_df.labelcode\n",
    "\n",
    "# Split the data into train/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.30, random_state=98052)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Rows in X_train 1711 : \n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    1526\n1     185\nName: labelcode, dtype: int64"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Count of label 0 and 1 in the training data set\n",
    "print(\"Rows in X_train %d : \" % len(X_train))\n",
    "type(X_train.values.tolist())\n",
    "\n",
    "y_train.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    660\n1     74\nName: labelcode, dtype: int64"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Count of label 0 and 1 in the test data set\n",
    "y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the dataset ready for using RandomUnderSampler\n",
    "X_train_np = X_train.to_numpy()\n",
    "X_test_np =  X_test.to_numpy()\n",
    "\n",
    "# Convert 1D to 2D (used as input to sampler)\n",
    "X_train_np2D = np.reshape(X_train_np,(-1,1))\n",
    "X_test_np2D = np.reshape(X_test_np,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference materials.\n",
    "#https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html\n",
    "#https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/applications/plot_topic_classication.html#sphx-glr-auto-examples-applications-plot-topic-classication-py\n",
    "#https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets\n",
    "\n",
    "\n",
    "# Perform random under-sampling\n",
    "sampler = RandomUnderSampler(random_state = 98053)\n",
    "X_train_rus, Y_train_rus = sampler.fit_resample(X_train_np2D, y_train)\n",
    "X_test_rus, Y_test_rus = sampler.fit_resample(X_test_np2D, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Resampled Training dataset  Counter({0: 187, 1: 187})\nResampled Test dataset Counter({0: 92, 1: 92})\n"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print('Resampled Training dataset  %s' % Counter(Y_train_rus))\n",
    "print('Resampled Test dataset %s' % Counter(Y_test_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the resampled datasets\n",
    "# flatten train and test dataset \n",
    "X_train_df = pd.DataFrame(X_train_rus.flatten())\n",
    "X_test_df = pd.DataFrame(X_test_rus.flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Dataset - Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's start off with the DistilBert Model\n",
    "# Load the DistilBERT model\n",
    "model_class, tokenizer_class, pretrained_weights = (tfs.DistilBertModel, tfs.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You will observe that the input sequence length is greater than the 512 characters, that is supported by the DistilBert model\n",
    "# There are different ways to address it.\n",
    "tokenized = X_train_df[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, truncation=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0      [101, 1012, 1012, 9385, 2230, 1011, 2355, 9733...\n1      [101, 1001, 14925, 2015, 4708, 20497, 1001, 10...\n2      [101, 1001, 1001, 22091, 2015, 3465, 10566, 31...\n3      [101, 1001, 22091, 2015, 12935, 2078, 2491, 10...\n4      [101, 1001, 22091, 2015, 3729, 2243, 4973, 202...\n                             ...                        \n365    [101, 1001, 22091, 2015, 1011, 1041, 2497, 101...\n366    [101, 1008, 1008, 1008, 3602, 1024, 2023, 2622...\n367    [101, 1001, 14305, 1011, 4111, 1011, 8866, 103...\n368                                           [101, 102]\n369                                           [101, 102]\nName: 0, Length: 370, dtype: object"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Longformer to handle text > 512 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/transformers/model_doc/longformer.html\\\n",
    "# Paper - http://arxiv.org/pdf/2004.05150.pdf\n",
    "\n",
    "model = LongformerModel.from_pretrained('allenai/longformer-base-4096')\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Max length to be 4096 as expected by the Long Transfer, and truncation to be true\n",
    "tokenized = X_train_df[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=2048, truncation=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pandas.core.series.Series"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "type(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(370,)"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "tokenized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "512\n"
    }
   ],
   "source": [
    "# we need to pad all to the same size\n",
    "# the following code double-checks that the max_len is indeed 4096\n",
    "max_len = 0\n",
    "for v in tokenized.values:\n",
    "    if(len(v) > max_len):\n",
    "        max_len = len(v)\n",
    "\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad all the lists to the same size\n",
    "# This will enable us to represent the input as a single 2D array\n",
    "padded = np.array([v + [0] *(max_len-len(v)) for v in tokenized.values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(370, 512)"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "\n",
    "We need to create a variable to tell the model to ignore (mask) the padding that we have done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(370, 512)"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "attention_mask = np.where(padded !=0,1,0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model() function runs the README through LongTransformer\n",
    "# Results are returned via last_hidden_states\n",
    "import torch\n",
    "\n",
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "last_hidden_states = None\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([[[-3.9827e-01,  1.3014e-02, -8.8761e-02,  ..., -2.2338e-01,\n            2.6989e-01,  5.5371e-01],\n          [ 1.8427e-01, -3.2230e-01,  1.0787e+00,  ...,  6.8759e-01,\n            1.3747e+00, -4.5151e-01],\n          [-6.9678e-01, -8.4625e-02,  8.5723e-01,  ...,  5.3232e-01,\n            7.3335e-01, -1.2424e-01],\n          ...,\n          [ 1.3377e-01,  2.1066e-01,  3.2894e-01,  ...,  2.0280e-01,\n           -3.6412e-04,  1.1656e-01],\n          [ 6.9400e-01,  1.4509e-01, -1.0994e-01,  ...,  1.1199e-02,\n           -9.8157e-02, -7.9229e-02],\n          [ 1.1844e-01,  3.9142e-01,  2.0955e-01,  ...,  3.2869e-01,\n           -3.5963e-01, -3.2384e-01]],\n \n         [[-3.1393e-01, -2.1880e-01, -2.2175e-02,  ..., -3.4022e-02,\n            4.4059e-01,  4.2828e-01],\n          [-7.8373e-01,  3.2684e-01,  3.1467e-01,  ...,  2.8760e-01,\n            3.4433e-01,  5.8296e-01],\n          [-6.2095e-01,  4.3895e-01,  5.0606e-01,  ...,  4.3861e-01,\n            8.9414e-01,  3.8678e-01],\n          ...,\n          [ 2.1770e-01,  3.8124e-02,  3.8134e-01,  ...,  4.1293e-01,\n            2.9049e-01, -6.9732e-01],\n          [-5.9747e-01, -1.2864e-01,  3.5398e-01,  ...,  2.9291e-01,\n           -1.3346e-02,  4.7864e-01],\n          [-6.2440e-01,  1.7426e-01,  6.0978e-01,  ...,  8.0053e-01,\n            1.1345e-01, -8.4364e-02]],\n \n         [[-3.2395e-01, -1.5047e-01, -2.1852e-01,  ..., -1.5152e-01,\n            1.8919e-01,  4.2936e-01],\n          [-5.3870e-01,  2.7369e-01,  3.4008e-01,  ...,  1.8394e-01,\n            3.5508e-01,  4.8995e-01],\n          [-9.1094e-01,  3.2993e-01,  4.2173e-01,  ...,  4.1727e-03,\n           -2.9720e-01,  3.6231e-01],\n          ...,\n          [ 9.0079e-01,  1.4787e-01,  2.3233e-01,  ..., -2.4813e-01,\n           -3.6629e-01, -2.4955e-01],\n          [-9.1864e-03, -5.6537e-02,  2.7163e-01,  ...,  3.7100e-01,\n           -2.3069e-01, -5.2099e-01],\n          [ 8.9947e-01,  1.1517e-01, -2.4100e-01,  ...,  2.5103e-01,\n           -5.3733e-01, -3.9304e-01]],\n \n         ...,\n \n         [[-1.1704e-01, -2.8513e-01,  1.9552e-02,  ...,  4.9211e-02,\n            3.2110e-01,  4.6019e-01],\n          [-7.2066e-01,  1.4099e-01,  2.1283e-01,  ...,  1.6165e-01,\n            7.2694e-02,  1.1497e+00],\n          [ 1.1210e-01,  2.0054e-01,  3.0958e-01,  ..., -1.9220e-01,\n           -1.2342e-01,  3.8113e-01],\n          ...,\n          [ 4.1688e-01, -1.0439e-01, -9.3852e-03,  ..., -7.8051e-02,\n            1.8091e-01, -5.4300e-01],\n          [ 1.4327e-01,  2.4712e-03,  1.5316e-02,  ...,  2.3085e-01,\n            1.6502e-02, -2.4638e-01],\n          [ 7.1706e-01,  2.0362e-01, -5.0618e-02,  ...,  3.7556e-01,\n           -4.7727e-01, -2.2929e-01]],\n \n         [[-1.8909e-01, -5.9448e-02,  3.6934e-02,  ..., -7.1568e-02,\n            1.3281e-01,  2.2173e-01],\n          [ 8.4196e-01,  9.1287e-02, -3.0830e-01,  ...,  2.8146e-01,\n           -6.8062e-01, -3.0149e-01],\n          [-1.6015e-01,  1.1105e-01,  5.5833e-02,  ...,  2.2901e-01,\n            1.0748e-01,  3.0387e-01],\n          ...,\n          [-5.1721e-02,  1.1391e-01,  1.1198e-01,  ...,  2.1373e-01,\n            2.8217e-02,  2.6641e-01],\n          [-4.8361e-02,  1.3333e-01,  1.2160e-01,  ...,  1.9923e-01,\n            4.5226e-02,  1.9091e-01],\n          [ 1.1167e-02,  7.8295e-02,  2.2944e-01,  ...,  2.1222e-01,\n           -6.8578e-03,  9.2415e-02]],\n \n         [[-1.8909e-01, -5.9448e-02,  3.6934e-02,  ..., -7.1568e-02,\n            1.3281e-01,  2.2173e-01],\n          [ 8.4196e-01,  9.1287e-02, -3.0830e-01,  ...,  2.8146e-01,\n           -6.8062e-01, -3.0149e-01],\n          [-1.6015e-01,  1.1105e-01,  5.5833e-02,  ...,  2.2901e-01,\n            1.0748e-01,  3.0387e-01],\n          ...,\n          [-5.1721e-02,  1.1391e-01,  1.1198e-01,  ...,  2.1373e-01,\n            2.8217e-02,  2.6641e-01],\n          [-4.8361e-02,  1.3333e-01,  1.2160e-01,  ...,  1.9923e-01,\n            4.5226e-02,  1.9091e-01],\n          [ 1.1167e-02,  7.8295e-02,  2.2944e-01,  ...,  2.1222e-01,\n           -6.8578e-03,  9.2415e-02]]]),)"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    " last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the output and save the features we need into the features variable\n",
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Y_train_rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "best parameters:  {'C': 73.68423684210526}\nbest scrores:  0.704025974025974\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
    "grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('best parameters: ', grid_search.best_params_)\n",
    "print('best scrores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "73.68423684210526"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "grid_search.best_params_[\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LogisticRegression(C=73.68423684210526)"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C =grid_search.best_params_[\"C\"] )\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6989247311827957"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "lr_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dummy classifier score: 0.473 (+/- 0.11)\n"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_train,y_train)\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}